{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dacite import from_dict\n",
    "from dacite import Config as DaciteConfig\n",
    "from llm_trainer import LLMTrainer, Evaluator\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from transformers import AutoTokenizer\n",
    "from xlstm import xLSTMLMModel, xLSTMLMModelConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/nick/anaconda3/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=768', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__', '-isystem', '/home/nick/anaconda3/envs/xlstm/targets/x86_64-linux/include'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=768', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__', '-isystem', '/home/nick/anaconda3/envs/xlstm/targets/x86_64-linux/include']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/nick/.cache/torch_extensions/py311_cu126 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/nick/.cache/torch_extensions/py311_cu126/slstm_HS768BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...\n",
      "/home/nick/anaconda3/envs/xlstm/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module slstm_HS768BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module slstm_HS768BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "/home/nick/anaconda3/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n",
      "/home/nick/anaconda3/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/nick/anaconda3/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=768', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__', '-isystem', '/home/nick/anaconda3/envs/xlstm/targets/x86_64-linux/include'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=768', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__', '-isystem', '/home/nick/anaconda3/envs/xlstm/targets/x86_64-linux/include']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/nick/.cache/torch_extensions/py311_cu126 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module slstm_HS768BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skipping build step...\n",
      "Loading extension module slstm_HS768BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n",
      "=========== cp_1000.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤══════════╕\n",
      "│ Benchmark    │ Metric     │    Value │\n",
      "╞══════════════╪════════════╪══════════╡\n",
      "│ HellaSwag    │ Accuracy   │   0.2586 │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ LAMBADA      │ Perplexity │ 259.01   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-103 │ Perplexity │ 179.76   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-2   │ Perplexity │ 179.76   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ PTB          │ Perplexity │ 183.95   │\n",
      "╘══════════════╧════════════╧══════════╛\n",
      "=========== cp_2000.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤══════════╕\n",
      "│ Benchmark    │ Metric     │    Value │\n",
      "╞══════════════╪════════════╪══════════╡\n",
      "│ HellaSwag    │ Accuracy   │   0.2626 │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ LAMBADA      │ Perplexity │ 176.15   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-103 │ Perplexity │ 108.78   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-2   │ Perplexity │ 108.78   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ PTB          │ Perplexity │ 122.8    │\n",
      "╘══════════════╧════════════╧══════════╛\n",
      "=========== cp_3000.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤══════════╕\n",
      "│ Benchmark    │ Metric     │    Value │\n",
      "╞══════════════╪════════════╪══════════╡\n",
      "│ HellaSwag    │ Accuracy   │   0.2644 │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ LAMBADA      │ Perplexity │ 135.9    │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-103 │ Perplexity │  82.59   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-2   │ Perplexity │  82.59   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ PTB          │ Perplexity │ 100.28   │\n",
      "╘══════════════╧════════════╧══════════╛\n",
      "=========== cp_4000.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤══════════╕\n",
      "│ Benchmark    │ Metric     │    Value │\n",
      "╞══════════════╪════════════╪══════════╡\n",
      "│ HellaSwag    │ Accuracy   │   0.2762 │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ LAMBADA      │ Perplexity │ 114.33   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-103 │ Perplexity │  72.43   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-2   │ Perplexity │  72.43   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ PTB          │ Perplexity │  93.97   │\n",
      "╘══════════════╧════════════╧══════════╛\n",
      "=========== cp_5000.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤══════════╕\n",
      "│ Benchmark    │ Metric     │    Value │\n",
      "╞══════════════╪════════════╪══════════╡\n",
      "│ HellaSwag    │ Accuracy   │   0.2786 │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ LAMBADA      │ Perplexity │ 106.71   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-103 │ Perplexity │  65.37   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-2   │ Perplexity │  65.37   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ PTB          │ Perplexity │  85.92   │\n",
      "╘══════════════╧════════════╧══════════╛\n",
      "=========== cp_6000.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤═════════╕\n",
      "│ Benchmark    │ Metric     │   Value │\n",
      "╞══════════════╪════════════╪═════════╡\n",
      "│ HellaSwag    │ Accuracy   │   0.276 │\n",
      "├──────────────┼────────────┼─────────┤\n",
      "│ LAMBADA      │ Perplexity │ 106.39  │\n",
      "├──────────────┼────────────┼─────────┤\n",
      "│ WikiText-103 │ Perplexity │  64.82  │\n",
      "├──────────────┼────────────┼─────────┤\n",
      "│ WikiText-2   │ Perplexity │  64.82  │\n",
      "├──────────────┼────────────┼─────────┤\n",
      "│ PTB          │ Perplexity │  82.39  │\n",
      "╘══════════════╧════════════╧═════════╛\n",
      "=========== cp_7000.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤══════════╕\n",
      "│ Benchmark    │ Metric     │    Value │\n",
      "╞══════════════╪════════════╪══════════╡\n",
      "│ HellaSwag    │ Accuracy   │   0.2778 │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ LAMBADA      │ Perplexity │ 104.38   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-103 │ Perplexity │  64.01   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-2   │ Perplexity │  64.01   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ PTB          │ Perplexity │  83.72   │\n",
      "╘══════════════╧════════════╧══════════╛\n",
      "=========== cp_8000.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤══════════╕\n",
      "│ Benchmark    │ Metric     │    Value │\n",
      "╞══════════════╪════════════╪══════════╡\n",
      "│ HellaSwag    │ Accuracy   │   0.2784 │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ LAMBADA      │ Perplexity │ 105.56   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-103 │ Perplexity │  63.21   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-2   │ Perplexity │  63.21   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ PTB          │ Perplexity │  83.93   │\n",
      "╘══════════════╧════════════╧══════════╛\n",
      "=========== cp_9000.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤══════════╕\n",
      "│ Benchmark    │ Metric     │    Value │\n",
      "╞══════════════╪════════════╪══════════╡\n",
      "│ HellaSwag    │ Accuracy   │   0.2793 │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ LAMBADA      │ Perplexity │ 103.85   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-103 │ Perplexity │  63.32   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ WikiText-2   │ Perplexity │  63.32   │\n",
      "├──────────────┼────────────┼──────────┤\n",
      "│ PTB          │ Perplexity │  84.22   │\n",
      "╘══════════════╧════════════╧══════════╛\n",
      "=========== cp_9999.pth ===========\n",
      "\n",
      "Evaluating on HellaSwag...\n",
      "\n",
      "Evaluating on LAMBADA...\n",
      "\n",
      "Evaluating on WikiText-103...\n",
      "\n",
      "Evaluating on WikiText-2...\n",
      "\n",
      "Evaluating on PTB...\n",
      "\n",
      "Evaluation Summary:\n",
      "╒══════════════╤════════════╤═════════╕\n",
      "│ Benchmark    │ Metric     │   Value │\n",
      "╞══════════════╪════════════╪═════════╡\n",
      "│ HellaSwag    │ Accuracy   │    0.28 │\n",
      "├──────────────┼────────────┼─────────┤\n",
      "│ LAMBADA      │ Perplexity │  102.47 │\n",
      "├──────────────┼────────────┼─────────┤\n",
      "│ WikiText-103 │ Perplexity │   62.56 │\n",
      "├──────────────┼────────────┼─────────┤\n",
      "│ WikiText-2   │ Perplexity │   62.56 │\n",
      "├──────────────┼────────────┼─────────┤\n",
      "│ PTB          │ Perplexity │   82.25 │\n",
      "╘══════════════╧════════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "checkpoints = sorted(os.listdir(\"checkpoints_xlstm\"))\n",
    "cfg = OmegaConf.load(\"xlstm_config.yaml\")\n",
    "cfg = from_dict(data_class=xLSTMLMModelConfig, data=OmegaConf.to_container(cfg), config=DaciteConfig(strict=True))\n",
    "xLSTM = xLSTMLMModel(cfg)\n",
    "trainer = LLMTrainer(xLSTM)\n",
    "\n",
    "for cp in checkpoints:\n",
    "    print(f\"=========== {cp} ===========\")\n",
    "    trainer.load_checkpoint(os.path.join(\"checkpoints_xlstm\", cp))\n",
    "    evaluator.eval_all(model=trainer.model,\n",
    "                    tokenizer=AutoTokenizer.from_pretrained(\"gpt2\"),\n",
    "                    return_logits=True,\n",
    "                    max_length=256,\n",
    "                    stride=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
